{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "694066d3",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: center; background-color: #0C6B44; font-family:newtimeroman; color: white; padding: 14px; line-height: 1;border-radius:20px\">ðŸ“Š**Forecasting on Data Science classify emails Prediction Dataset**</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c072991a",
   "metadata": {},
   "source": [
    "# Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5765bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing needed packages here\n",
    "\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from spacy.matcher import Matcher\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from tqdm import tqdm \n",
    "cpu_count = int(os.cpu_count()) if os.cpu_count() != None else 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf56106",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eed0ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.read_csv('data/mapping.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "597b7941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>language</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello, Does it matter iff I use Visa or Master...</td>\n",
       "      <td>7-6-2022</td>\n",
       "      <td>visa_or_mastercard</td>\n",
       "      <td>en</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good afternoon, I just got refunded for my pur...</td>\n",
       "      <td>16-11-2022</td>\n",
       "      <td>reverted_card_payment?</td>\n",
       "      <td>en</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello, I got billed ann extra pound! Thanks</td>\n",
       "      <td>4-12-2022</td>\n",
       "      <td>extra_charge_on_statement</td>\n",
       "      <td>en</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi, How long does it take for a transfer to sh...</td>\n",
       "      <td>23-11-2022</td>\n",
       "      <td>transfer_timing</td>\n",
       "      <td>en</td>\n",
       "      <td>transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi, When can I use money sent to my accountt? ...</td>\n",
       "      <td>17-4-2022</td>\n",
       "      <td>transfer_timing</td>\n",
       "      <td>en</td>\n",
       "      <td>transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9068</th>\n",
       "      <td>good afternoon, I think someone may be using m...</td>\n",
       "      <td>22-6-2022</td>\n",
       "      <td>compromised_card</td>\n",
       "      <td>en</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9069</th>\n",
       "      <td>good morning, Help, I need to top up my accoun...</td>\n",
       "      <td>7-4-2022</td>\n",
       "      <td>top_up_by_cash_or_cheque</td>\n",
       "      <td>en</td>\n",
       "      <td>cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9070</th>\n",
       "      <td>hi, I made an international purchasee, but the...</td>\n",
       "      <td>7-12-2022</td>\n",
       "      <td>card_payment_wrong_exchange_rate</td>\n",
       "      <td>en</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9071</th>\n",
       "      <td>hi, Why is my card not working anymore? Thanks</td>\n",
       "      <td>1-11-2022</td>\n",
       "      <td>card_not_working</td>\n",
       "      <td>en</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9072</th>\n",
       "      <td>Hello, How many different cards can I havee fo...</td>\n",
       "      <td>24-4-2022</td>\n",
       "      <td>getting_spare_card</td>\n",
       "      <td>en</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9038 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text        date  \\\n",
       "0     Hello, Does it matter iff I use Visa or Master...    7-6-2022   \n",
       "1     Good afternoon, I just got refunded for my pur...  16-11-2022   \n",
       "2           Hello, I got billed ann extra pound! Thanks   4-12-2022   \n",
       "3     Hi, How long does it take for a transfer to sh...  23-11-2022   \n",
       "4     hi, When can I use money sent to my accountt? ...   17-4-2022   \n",
       "...                                                 ...         ...   \n",
       "9068  good afternoon, I think someone may be using m...   22-6-2022   \n",
       "9069  good morning, Help, I need to top up my accoun...    7-4-2022   \n",
       "9070  hi, I made an international purchasee, but the...   7-12-2022   \n",
       "9071     hi, Why is my card not working anymore? Thanks   1-11-2022   \n",
       "9072  Hello, How many different cards can I havee fo...   24-4-2022   \n",
       "\n",
       "                              category language     class  \n",
       "0                   visa_or_mastercard       en      card  \n",
       "1               reverted_card_payment?       en      card  \n",
       "2            extra_charge_on_statement       en    others  \n",
       "3                      transfer_timing       en  transfer  \n",
       "4                      transfer_timing       en  transfer  \n",
       "...                                ...      ...       ...  \n",
       "9068                  compromised_card       en      card  \n",
       "9069          top_up_by_cash_or_cheque       en      cash  \n",
       "9070  card_payment_wrong_exchange_rate       en      card  \n",
       "9071                  card_not_working       en      card  \n",
       "9072                getting_spare_card       en      card  \n",
       "\n",
       "[9038 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/dataset.csv')\n",
    "dataset = dataset[dataset.language=='en']\n",
    "dataset = pd.merge(dataset, mapping, how='left')\n",
    "dataset = dataset[~dataset[\"class\"].isna()]\n",
    "#dataset.isna().sum()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659081ed",
   "metadata": {},
   "source": [
    "# Setting methods for preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b01fcf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9038/9038 [00:23<00:00, 384.88it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = WordPunctTokenizer()\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "docs = list(tqdm(nlp.pipe(dataset['text']),total=len(dataset['text'])))\n",
    "en_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    text = re.sub(r\"[^\\w\\d\\s]\", \"\", text)\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stopwords(text, stopwords):\n",
    "    words = [word for word in tokenizer.tokenize(text) if word not in stopwords]\n",
    "    text_processed = \" \".join(words)\n",
    "    return text_processed\n",
    "def apply_stemmer (text,stemmer):\n",
    "    words = [stemmer.stem(word) for word in text.split() ]\n",
    "    return ' '.join(words)\n",
    "def regex (text):\n",
    "    \n",
    "    return re.sub(r'(Kind Regards|kind Regards|Best Regards|thanks|best Regards|Thanks)$','',re.sub(r'^[\\w\\s]+\\,','',text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "461addd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>does it matter iff i use visa or mastercard</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i just got refunded for my purchase over two ...</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i got billed ann extra pound</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how long does it take for a transfer to show ...</td>\n",
       "      <td>transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when can i use money sent to my accountt</td>\n",
       "      <td>transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9068</th>\n",
       "      <td>i think someone may be using my card</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9069</th>\n",
       "      <td>help i need to top up my account where do i s...</td>\n",
       "      <td>cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9070</th>\n",
       "      <td>i made an international purchasee but the exc...</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9071</th>\n",
       "      <td>why is my card not working anymore</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9072</th>\n",
       "      <td>how many different cards can i havee for my a...</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9038 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     class\n",
       "0          does it matter iff i use visa or mastercard       card\n",
       "1      i just got refunded for my purchase over two ...      card\n",
       "2                         i got billed ann extra pound     others\n",
       "3      how long does it take for a transfer to show ...  transfer\n",
       "4             when can i use money sent to my accountt   transfer\n",
       "...                                                 ...       ...\n",
       "9068              i think someone may be using my card       card\n",
       "9069   help i need to top up my account where do i s...      cash\n",
       "9070   i made an international purchasee but the exc...      card\n",
       "9071                why is my card not working anymore       card\n",
       "9072   how many different cards can i havee for my a...      card\n",
       "\n",
       "[9038 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(df):   \n",
    "    df_processed = df.copy()  \n",
    "    df_processed[\"text\"] = df_processed[\"text\"].apply(regex)\n",
    "    df_processed[\"text\"] = df_processed[\"text\"].apply(remove_punctuation)\n",
    "#     df_processed[\"text\"] = df_processed[\"text\"].apply(remove_stopwords, stopwords = en_stopwords)   \n",
    "#     df_processed[\"text\"] = df_processed[\"text\"].apply(apply_stemmer, stemmer = SnowballStemmer(\"english\", ignore_stopwords=True))   \n",
    "    return df_processed\n",
    "\n",
    "dataset_processed = preprocess_text(dataset)\n",
    "dataset_processed.drop(columns = ['category','language','date'],inplace=True)\n",
    "dataset_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b81f5d",
   "metadata": {},
   "source": [
    "# Best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9082c7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_with_tfidf(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    pipe = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('classifier', SVC(C=5))])\n",
    "#                     ('classifier', RandomForestClassifier(random_state=42))])\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    \n",
    "    f1s = f1_score(y_pred, y_test, average='macro')\n",
    "    return pipe, f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f82d265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset_processed[\"text\"], dataset_processed[\"class\"], \n",
    "                                                    test_size=0.2, random_state=42, stratify=dataset_processed[\"class\"])\n",
    "\n",
    "baseline_model, baseline_f1s = baseline_with_tfidf(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c07745",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be651958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9398225033267688"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2954f17",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fde988e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher= Matcher(nlp.vocab)\n",
    "matcher.add('ADJ',[[{\"POS\":'ADJ'}]])\n",
    "matcher.add('ADV',[[{\"POS\":'ADV'}]])\n",
    "nb_adj_adv = [len(matcher(doc)) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fcb36f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_processed[\"nb_words\"] = dataset_processed['text'].str.split().map(len)\n",
    "dataset_processed[\"doc_length\"] = dataset_processed['text'].map(len)\n",
    "dataset_processed[\"nb_adj_adv\"] = nb_adj_adv\n",
    "dataset_processed[\"avg_word_length\"] = dataset_processed['text'].apply(lambda x: np.mean([len(t) for t in x.split() ]) if len([len(t) for t in x.split()]) > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4cd1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset_processed.drop(columns= [\"class\"]), dataset_processed[\"class\"], \n",
    "                                                    test_size=0.2, random_state=42, stratify=dataset_processed[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1432d3d6",
   "metadata": {},
   "source": [
    "# Making Feature union "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53395dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a column from the dataframe to perform additional transformations on\n",
    "    \"\"\" \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "\n",
    "class TextSelector(Selector):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "    \n",
    "class NumberSelector(Selector):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a4a2e",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b70d24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9388193593474707"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipe = Pipeline([('selector', TextSelector(\"text\")),\n",
    "    ('tfidf',TfidfVectorizer())])\n",
    "\n",
    "\n",
    "nb_words_pipe = Pipeline([('selector', NumberSelector(\"nb_words\")),\n",
    "                ('standard', StandardScaler())])\n",
    "doc_length_pipe = Pipeline([('selector', NumberSelector(\"doc_length\")),\n",
    "                ('standard', StandardScaler())])\n",
    "avg_word_length_pipe = Pipeline([('selector', NumberSelector(\"avg_word_length\")),\n",
    "                ('standard', StandardScaler())])\n",
    "feats = FeatureUnion([('text', text_pipe), \n",
    "                     ])\n",
    "combined_pipe = Pipeline([\n",
    "    ('feats',feats),\n",
    "    ('clf',  SVC(C=20)),\n",
    "    ])\n",
    "combined_pipe.fit(X_train,y_train)\n",
    "pred= combined_pipe.predict(X_test)\n",
    "score = f1_score(y_test,pred,average='macro')\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
